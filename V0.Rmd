---
title: "EA - Analisis OVNIs"
output: html_notebook
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

# Intro

En este projecto usaremos el fichero de datos "scrubbed.csv" obtenido en <https://www.kaggle.com/datasets/NUFORC/ufo-sightings>. Elimininaremos datos de tipo NA y cambiaremos paises vacios (i.e. pais == "") por "*Otros*". Tambien arreglamos el formato de los datos con la libreria *lubridate*. Usamos la libreria *dplyr* para eliminar columnas no necesarias.

```{r}
# Leemos datos de CSV
datos <- read.csv("scrubbed.csv")

# Reemplacamos paises "" por "Otros"
datos$country <- ifelse(datos$country=="","otros",datos$country)

# Formateamos datos
datos$datetime <- as.POSIXct(datos$datetime, format =  "%m/%d/%Y %H:%M")
datos$'duration (seconds)' <- as.integer(datos$'duration..seconds.')
datos$latitude <- as.numeric(datos$latitude)

# Eliminamos datos NA
datos <- na.omit(datos)

library(dplyr)

datos <- datos %>% select(-one_of('duration..seconds.', 'duration..hours.min.', 'date.posted'))
```

Analisando los datos por pais, podemos ver que la mayoria de los OVNIs reportados son en EEUU. Usaremos la libreria *ggplot2* para generar diagrama, y representamos el diagrama de numero de OVNIs por pais

```{r}
by_country <- aggregate(datos$country, by=list(Country = datos$country), FUN=length)

library(ggplot2)

ggplot(by_country, aes(x="", y=by_country$x, fill=by_country$Country)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  xlab("") +
  ylab("") +
  guides(fill = guide_legend(title = "Pais"))
```

Por eso, hemos decidido hacer nuestros analisis sobre datos solamente de EEUU. Tomamos una prueba de tamaño 1000

```{r}
datos_us <- datos[which(datos$country == 'us'),]

datos_us <- datos_us %>% select(-country)

datos_us <- datos_us[sample(nrow(datos_us), 1000), ]
```

# Tema 3 - Estadística Descriptiva y Regresión (Axel)
De la prueba de 1000 datos, se ha hecho el análisis solamente de las variables cuantitativas, las cuales son: ("datetime, latitude, longitude, duration(seconds)")
Con el comando names(object...) se puede ver todas las columnas del fichero de datos y las referenciadas anteriormente
```{r}
names(datos_us)
```

## Medidas de Posición - Tendencia Central y No Central

Con `summary(object...)` podemos ver la media, mediana y percentiles de varios datos, para calcular la moda usamos la funcion *mode*

#datetime
```{r}
summary(datos_us$datetime)

mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

print(paste("Moda: ", mode(datos_us$datetime)))
```
#latitude
```{r}
summary(datos_us$latitude)

mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

print(paste("Moda: ", mode(datos_us$latitude)))
```
#longitude
```{r}
summary(datos_us$longitude)

mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

print(paste("Moda: ", mode(datos_us$longitude)))
```
#duration (seconds)
```{r}
summary(datos_us$'duration (seconds)')

mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

print(paste("Moda: ", mode(datos_us$'duration (seconds)')))
```

## Medidas de Dispersión

No se ha considerado necesario calcular la varianza y desviación poblacional

| Medida | Formula |
|:------|-------:|
| Cuasivarianza | var(x) |
| Cuasidesviación típica | sd(x) |
| Coeficiente de variación | coef_var(x) |

#duration (seconds)
```{r}
varianza <- var(datos_us$'duration (seconds)')
print(paste("Cuasivarianza: ", varianza))

sd <- sd(datos_us$'duration (seconds)')
print(paste("Cuasidesviación típica: ", sd))

coef_var <- function(x) {
  sd(x) / mean(x)
}
cv <- coef_var(datos_us$'duration (seconds)')
print(paste("Coeficiente de variación: ", cv))

```
#latitude
```{r}
varianza <- var(datos_us$latitude)
print(paste("Cuasivarianza: ", varianza))

sd <- sd(datos_us$latitude)
print(paste("Cuasidesviación típica: ", sd))

coef_var <- function(x) {
  sd(x) / mean(x)
}
cv <- coef_var(datos_us$latitude)
print(paste("Coeficiente de variación: ", cv))

```
#longitude
```{r}
varianza <- var(datos_us$longitude)
print(paste("Cuasivarianza: ", varianza))

sd <- sd(datos_us$longitude)
print(paste("Cuasidesviación típica: ", sd))

coef_var <- function(x) {
  sd(x) / mean(x)
}
cv <- coef_var(datos_us$longitude)
print(paste("Coeficiente de variación: ", cv))

```
#datetime
```{r}
varianza <- var(datos_us$datetime)
print(paste("Cuasivarianza: ", varianza))

sd <- sd(datos_us$datetime)
print(paste("Cuasidesviación típica: ", sd))

```
## Medidas de Forma(Usar si no funciona: install.packages("moments"))
#latitude
Al calcular la asimetría y curtosis de la latitud determinamos que:
*Obtenemos una asimetría negativa, por tanto la mayoría de datos se encuentran a la derecha de la media.
*Obtenemos una curtosis mayor que cero, por tanto, hay una mayor concentración
de datos alrededor de la media
```{r}
library(moments)
x <- (datos_us$latitude)
print(kurtosis(x))
print(skewness(x))
print(mean(x))
hist(x)
```
#longitude
Al calcular la asimetría y curtosis de la latitud determinamos que:
*Obtenemos una asimetría negativa, por tanto la mayoría de datos se encuentran a la derecha de la media.
*Obtenemos una curtosis mayor que cero, por tanto, hay una mayor concentración
de datos alrededor de la media
```{r}
library(moments)
x <- (datos_us$longitude)
print(kurtosis(x))
print(skewness(x))
print(mean(x))
hist(x)
```
#datetime
Al calcular la asimetría y curtosis de la latitud determinamos que:
*Obtenemos una asimetría negativa, por tanto la mayoría de datos se encuentran a la derecha de la media.
*Obtenemos una curtosis mayor que cero, por tanto, hay una mayor concentración
de datos alrededor de la media
```{r}
library(moments)
x <- (datos_us$datetime)
print(kurtosis(x))
print(skewness(x))
hist(x, 50)
```
#duration (seconds)
Al calcular la asimetría y curtosis de la latitud determinamos que:
*Obtenemos una asimetría positiva, por tanto la mayoría de datos se encuentran a la izquierda de la media.
*Obtenemos una curtosis mayor que cero, por tanto, hay una mayor concentración
de datos alrededor de la media
```{r}
library(moments)
x <- (datos_us$'duration (seconds)')
print(kurtosis(x))
print(skewness(x))
print(mean(x))
hist(x)
```
##Gráficos asociados a la Tabla de Frecuencias para algunos datos(excepto histogramas, usados anteriormente para ver mejor las medidas de forma)
#Poligonos absolutos
#latitud
```{r}
lat <- datos_us$latitude
breaks <- seq(0, 90, by=10)
lat.cut <- cut(lat, breaks, right = FALSE)
lat.freq <- table(lat.cut)
lat.cumfreq <- c(0,cumsum(lat.freq))
plot(breaks, lat.cumfreq,
     main="Latitud de los ovnis",
     xlab = "Latitud",
     ylab = "Latitudes acumuladas")
lines(breaks, lat.cumfreq)
```
#longitude
```{r}
longitude <- datos_us$longitude
breaks <- seq(-200, 100, by=10)
longitude.cut <- cut(longitude, breaks, right = FALSE)
longitude.freq <- table(longitude.cut)
longitude.cumfreq <- c(0,cumsum(longitude.freq))
plot(breaks, longitude.cumfreq,
     main="Longitud de los ovnis",
     xlab = "Longitud",
     ylab = "Longitudes acumuladas")
lines(breaks, longitude.cumfreq)
```

# Tema 4 - Probabilidad (Fonsi)

Probabilidad de ser de cada pais en caso de avistar un ovni

```{r}
dat <- read.csv("scrubbed.csv")
dat_country<-aggregate(dat$country, by=list(Country = dat$country), FUN=length)
dat$country <- ifelse(dat$country=="","otros",dat$country)
numAvistamientos<-count(dat)
proobau1<-dat_country[which(dat_country$Country == 'au'),]
proobau2<-dat_country[which(dat_country$Country == 'ca'),]
proobau3<-dat_country[which(dat_country$Country == 'de'),]
proobau4<-dat_country[which(dat_country$Country == 'gb'),]
proobau5<-dat_country[which(dat_country$Country == 'us'),]
proobau6<-dat_country[which(dat_country$Country == ''),]
probbauval1<-(proobau1$x/numAvistamientos)*100
probbauval2<-(proobau2$x/numAvistamientos)*100
probbauval3<-(proobau3$x/numAvistamientos)*100
probbauval4<-(proobau4$x/numAvistamientos)*100
probbauval5<-(proobau5$x/numAvistamientos)*100
probbauval6<-(proobau6$x/numAvistamientos)*100



print(paste("La probabilidad de avistar un ovni en Australia es del: ",probbauval1,"%"))

print(paste("La probabilidad de avistar un ovni en Canadá es del: ",probbauval2,"%"))

print(paste("La probabilidad de avistar un ovni en Alemania es del: ",probbauval3,"%"))

print(paste("La probabilidad de avistar un ovni en Gran Bretaña es del: ",probbauval4,"%"))

print(paste("La probabilidad de avistar un ovni en Estados Unidos es del: ",probbauval5,"%"))

print(paste("La probabilidad de avistar un ovni en otros países es del: ",probbauval6,"%"))
```

Debido a que es  en Estados Unidos donde hay mayor probabilidad de avistar un UFO vamos a calcular las ciudades donde es mas probable lograrlo


```{r}
by_city <- aggregate(datos_us$city, by=list(City = datos_us$city), FUN=length)
mostseek<-by_city[which(by_city$x>4),]

maxcity<-by_city[which(by_city$x == max(by_city$x)),]
print(paste("La ciudad con mayor probabilidad de avistar un ovni es",maxcity$City,"con una probabilidad de un ",(maxcity$x/count(by_city))*100,"%"))


ggplot(mostseek, aes(x="", y=mostseek$x, fill=mostseek$City)) +
  geom_bar(stat="identity", width=1) +
  xlab("") +
  ylab("") +
  guides(fill = guide_legend(title = "Pais" ))

plot(names.arg=mostseek$Country,mostseek$x,type="l",col="blue", xlab = "Ciudades", ylab = "Avistamientos", main = "Número de avistamientos en ciudades") 

anios<- aggregate(datos_us$city, by=list(Date = format(datos_us$datetime,"%Y")), FUN=length)

plot(anios$Date,anios$x,type="l",col="blue", xlab = "Linea temporal", ylab = "Avistamientos", main = "Número de avistamientos por año")
```


# Tema 5 - Variables Aleatorias y Modelos de Probabilidad (Sergio)

# Tema 6 - Muestreo, Estimación Puntual y por Intervalos de Confianza (Iñigo)

Vamos a construir un intervalo de confianza del 95% para la duracion media de los avistamientos en EEUU.
```{r}
datos <- read.csv("scrubbed.csv")#dataframe
datos_us <- datos[which(datos$country == "us"), ]#filtro por pais Estados Unidos
datos_us$"duration..seconds." <- as.integer(datos_us$"duration..seconds.")#convierto los valores a integer
datos_us <- datos_us[!is.na(datos_us$duration..seconds.), ]#eliminar NAs (en caso de que no se pudiera convertir a int algun valor)
retval <- subset(datos_us, duration..seconds. < 7201, select = c(state, duration..seconds.))#filtro por duracion menor o igual a 7200, para descartar valores muy altos que son inútiles nuestro análisis

intervalo <- t.test(retval$duration..seconds., conf.level = 0.95)#sacamos el intervalo de confianza
print(intervalo$conf.int)#intervalo de confianza
print(mean(retval$duration..seconds.))#media

print(paste("El resultado indica que la media de la variable duracion (seconds) es de ", mean(retval$duration..seconds.), " el cual se encuentra con una confianza del 95% en el intervalo ", intervalo$conf.int[1], " ", intervalo$conf.int[2]))

car::qqPlot(retval$duration..seconds., pch=19,
       main='QQplot para la duración de avistamientos',
       xlab='Cuantiles teóricos',
       ylab='Cuantiles muestrales')

hist(retval$duration..seconds., freq=TRUE,
     main='Histograma para la duración de avistamientos',
     xlab='Duracion (s)',
     ylab='Frecuencia')
     #Podemos observar que la mayoría de avistamientos duran muy poco tiempo.
```


# Tema 7 - Contrastes de Hipótesis (Nico)
